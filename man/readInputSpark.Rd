% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/core-functions-spark.R
\docType{class}
\name{readInputSpark}
\alias{readInputSpark}
\title{Function to initialize \code{SparkAnalysisRecipe} class with the input data frame}
\details{
The class which holds the metadata including the registry of available functions,
the data on which the recipe is to be applied, as well as the recipe itself. Overloads the initialization function
for Spark DataFrames

More details of how an object of this class should be initialized is provided in the
constructor - \link{initialize}
}
\section{Slots}{

\describe{
\item{\code{input}}{The input dataset on which analysis is to be performed}

\item{\code{filePath}}{Path of the input dataset to be uploaded}

\item{\code{recipe}}{A tibble which holds functions to be called}

\item{\code{registry}}{A tibble which holds all the registered functions}

\item{\code{output}}{A list which holds all the functions output}
}}

\seealso{
Other Package core functions: \code{\link{generateOutput}},
  \code{\link{generateReport}}, \code{\link{initialize}},
  \code{\link{loadRecipeSpark}}, \code{\link{loadRecipe}},
  \code{\link{readInput}},
  \code{\link{registerFunctionSpark}},
  \code{\link{registerFunction}}, \code{\link{saveRecipe}},
  \code{\link{sparkRSessionCreateIfNotPresent}},
  \code{\link{updateObject}}
}
