% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/core-functions-spark.R
\docType{class}
\name{readInputSpark}
\alias{readInputSpark}
\title{Function to initialize \code{SparkAnalysisPipeline} class with the input Spark DataFrame}
\details{
The class which holds the metadata including the registry of available functions,
the data on which the pipeline is to be applied, as well as the pipeline itself

More details of how an object of this class should be initialized is provided in the
constructor - \link{initialize}
}
\section{Slots}{

\describe{
\item{\code{input}}{The input Spark DataFrame on which analysis is to be performed}

\item{\code{workingInput}}{Internal slot for having a working version of the input}

\item{\code{pipeline}}{A tibble which holds functions to be called}

\item{\code{registry}}{A tibble which holds all the registered functions}

\item{\code{output}}{A list which holds all the functions output}
}}

\seealso{
Other Package core functions for Spark: \code{\link{initialize}},
  \code{\link{loadPipelineSpark}},
  \code{\link{registerFunctionSpark}}
}
