Package: analysisPipelines
Type: Package
Title: This Package Allows Data Scientists to Compose Interoperable Analysis Pipelines, and Put Them into Production
Version: 0.0.0.9004
Authors@R: c(
      person("Naren","Srinivasan", email = "naren1991@gmail.com", role = c("aut")),
      person("Zubin Dowlaty","",  email = "Zubin.Dowlaty@mu-sigma.com", role = c("ctb")),
      person("Sanjay","",  email = "Sanjay@mu-sigma.com", role = c("ctb")),
      person("Neeratyoy","Mallik", email = "Neeratyoy.Mallik@mu-sigma.com", role = c("ctb")),
		  person("Anoop S","",  email = "Anoop.S@mu-sigma.com", role = c("ctb")),
		  person("Mu Sigma, Inc.", email = "ird.experiencelab@mu-sigma.com", role = c("cre"))
		  )
Description: This package aims at enabling data scientists to compose pipelines of analysis which consist of data manipulation, exploratory analysis & reporting, as well as modeling steps. It also aims to enable data scientists to use tools of their choice through an R interface, and compose interoperable pipelines between R, Spark, and Python. Credits to Mu Sigma for supporting the development of the package.
Depends: R (>= 3.4.0), magrittr, pipeR, methods
Imports: ggplot2, dplyr, futile.logger, RCurl, proto, rlang, purrr, devtools
Suggests: plotly, knitr, rmarkdown, parallel, visNetwork, rjson, DT, shiny, R.devices, corrplot, reticulate
Encoding: UTF-8
License: Apache License 2.0
LazyLoad: yes
LazyData: yes
RoxygenNote: 6.1.1
VignetteBuilder: knitr
Collate: 
    'analysisPipelines_package.R'
    'core-functions.R'
    'core-functions-batch.R'
    'core-functions-meta-pipelines.R'
    'core-streaming-functions.R'
    'r-batch-eda-utilities.R'
    'r-helper-utilites-python.R'
    'spark-structured-streaming-utilities.R'
    'zzz.R'
